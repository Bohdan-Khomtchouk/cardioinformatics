\documentclass[letter]{bioinfo}
\copyrightyear{2018} \pubyear{2018}

\access{Advance Access Publication Date: (under review)}
\appnotes{Review article}
\graphicspath{{../figures/}}

\newcommand{\comment}[1]{\textcolor{red}{#1}}
\newcommand{\todo}[1]{\colorbox{yellow}{\parbox{1\linewidth}{#1}}}

\begin{document}
\firstpage{1}

\subtitle{Review}

\title[Cardioinformatics]{Cardioinformatics: the nexus of bioinformatics and cardiology}
\author[Sample \textit{et~al}.]{Bohdan B. Khomtchouk\,$^{\text{\sfb 1,2,3,}*}$, Diem-Trang Tran\,$^{\text{\sfb 4}}$, Or Gozani\,$^{\text{\sfb 1}}$, Themistocles L. Assimes\,$^{\text{\sfb 2, 3}}$}
\address{$^{\text{\sf 1}}$Department of Biology, Stanford University, Stanford, CA, USA \\
$^{\text{\sf 2}}$Department of Medicine, Division of Cardiovascular Medicine, Stanford University, Stanford, CA, USA \\
$^{\text{\sf 3}}$VA Palo Alto Health Care System, Palo Alto, CA, USA \\
$^{\text{\sf 4}}$School of Computing, University of Utah, Salt Lake City, UT, USA
}

\corresp{$^\ast$To whom correspondence should be addressed: \href{bohdan@stanford.edu}{bohdan@stanford.edu}}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{Cardiovascular disease (CVD) is the leading cause of death worldwide, causing over 17M deaths per year, which outpaces global cancer mortality rates.  Despite these sobering statistics, most bioinformatics and computational biology work to-date has been concentrated predominantly on cancer research, with a relatively small (almost invisible) footprint in CVD.  In this paper, we review the existing literary landscape and critically assess the unmet need to pioneer an emerging field at the multidisciplinary interface of bioinformatics and cardiology, which we refer to as "cardioinformatics".  To encourage reproducibility and verifiability of our results, all data and source code powering the data-driven visualizations and quantitative analyses presented in this review are provided at: https://github.com/Bohdan-Khomtchouk/cardioinformatics. \\
\textbf{Key words:} cardiovascular disease; bioinformatics; cardiology; computational biology}

\maketitle

\section*{Introduction}
%\section*{The current status of bioinformatics in cardiovascular disease research}

Cardiovascular diseases have persistently been the leading cause of death by non-communicable diseases in the US for the last two decades (Figure \ref{fig:figure1}A).  According to the World Health Organization, ischemic heart disease and stroke have remained the two top global killers in the last 15 years, with cancer (all cancers combined) coming in at number three.  The Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) shows that while heart disease and cancer have similar mortality rates in the US, heart disease is still the dominant cause of death globally for both genders (cite https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(18)32203-7/fulltext).  Research in CVD has steadily increased since the year 2000, as measured by the body of publications indexed in PubMed over this time (Figure \ref{fig:figure1}B).  In 2017 alone, there were more than 40000 primary research (non-review) articles classified with the subject heading "cardiovascular disease", defined according to the Medical Subject Heading (MeSH) terms.  This MeSH Database entry (\textit{cardiovascular disease}) includes many types of cardiovascular abnormalities that may occur in organs outside the immediate circulatory system.

% Something is wrong with this figure-- I get an overbox error when I uncomment it, like as if it doesn't fit the page.
%\begin{figure}
	%\centering
	%\includegraphics[width=1\linewidth]{figure1}
	%\caption{\textbf{A}. Number of deaths by Non-Communicable Diseases in the US. \textbf{B}. \textbf{C}.}
	%\label{fig:figure1}
%\end{figure}

Among these outputs, the share of bioinformatics research remains modest, almost invisible -- at least relative to analogous work in the cancer field (Figure \ref{fig:figure1}C). Despite being present in the current tide of precision medicine initiatives, cardiovascular research is critically lacking in bioinformatics research which is at the center of precision medicine \citep{Gomez-Lopez:2017:Precision}.  The modest contribution of bioinformatics in cardiology is in stark contrast to that in cancer, to some extent suggesting that there are ample opportunities for cardioinformatics. Despite being "complex diseases". In this review, we highlight the contemporary problems in the research of CVD genetics, introduce the bountiful resources available and propose the ways to advance this field and leverage cardiovascular research with bioinformatics.

The first draft of the human genome project had brought a lot of hope and excitement about potential advancements in the diagnosis and treatment of cardiac diseases, such as the ability to identify disease genes within the associated loci, to improve risk estimation based on more precise genotypes, or to personalize the prediction of drug effect on a patient, \citep{Komajda:2001:heart}.


Outstanding problems

Variant calling and pathogenicity prediction. Currently inconsistent. Mostly developed for protein-coding fraction of the genome (SIFT, Polyphen, etc.), largely ignore the non-coding regions.
Pathogenicity assignment: variable, conflicting, not applicable for all populations.

Risk estimation

Lack of mechanistic understanding

Lack of platforms for accessible data and knowledge base

%{https://www.ncbi.nlm.nih.gov/mesh/68002318} 

As we further our quest to understand the genetics of heart diseases, many conditions have become too complicated for traditional approaches. Reflecting on the current body of knowledge, we recognize that many aspects of this complexity can be addressed with more computational methods.



\section{Complexity of CVDs}  % the problems

\subsection{The number of actors}

% large number --> small effects
% large number --> more interactions, intra and inter-pathways
% 
There are a certain genetic component in all major categories of heart diseases (Figure \ref{fig:hpo_gene_count}). As more studies are published, the number of genes found associated with a disease has also increased and in most cases, gone beyond a few genes that could be described in a single-page table or diagram.

Dilated cardiomyopathy (DCM), the most common cause of heart transplantation, is a vivid example of how causal variants and their corresponding genes kept being discovered. In a recent review \citep{Burke:2016:Clinical} 16 disease-causing genes were compiled, along with an additional 41 putative genes. Meanwhile, GWAS catalog and HPO annotation suggested a much larger number of genes associated with this condition, 69 genes and 115 genes, respectively. Clinical application is keeping up, with a typical commercial gene panel for DCM genetic testing cover 50 genes on average, and 111 in total \citep{McNally:2017:Dilated}.
%These numbers clearly advocate for more bioinformatics analyses to gain insights into this condition and the other conditions that are equivalently complex.
Since it is reasonably expected that when more genes are involved in a disease, the effect exerted by each gene gets smaller, these ever-enlarging gene panels suggest that the risks conferred by mutations in a single gene is less likely to be indicative of the disease risk.
%Recent study asserted the negative correlation between minor allele frequency and the effect size across all tissues (liver, skeletal muscle, adipose tissue, atherosclerotic aortic root, artery and blood) in the Stockholm-Tartu Atherosclerosis Reverse Networks Engineering Task study (STARNET) \citep{Franzen:2016:Cardiometabolic} \comment{Figure S17}.
From the research perspective, they imply that the quest of pinpointing the causal variants is getting more difficult, because testing the variant-phenotype association on small-effect variations requires a much larger number of samples for sufficient power, or critically different methods of statistical testing and inference.\comment{Check refs. Elaborate on current efforts to have large study populations and to devise new way to fish for those associations.}

Beside the increasing difficulty discovering these genes, modeling of their effects is speedily complicated. With a potential interaction between every pair of genomic features, be they genes or regulatory sequences, the number of such interactions increase quadratically with the number of actors, leading to the combinatorial explosion of states that a biological system can assume. \comment{ethnicity and ancestry may be mentioned here}

The number of genes contributing to CVD risks will likely inflate beyond those directly associated with diseased traits. Independent research in aging has unraveled the intertwined relation between heart disease and longevity pathways \citep{North:2012:Intersection}.  With age being the most important factor in constituting cardiovascular risk \citep{Steenman:2017:Cardiac}, it is unavoidable that an even larger number of genes and pathways will be involved in future analyses of CVD genetics. In the recent omnigenic model for complex traits, it is proposed that most heritability of these traits is explained by peripheral genes outside of the core pathways. Following this model, future analyses of CVD might need to include thousands of genes to model a single disease.
%does it help to have too many variants in a genetic risk score?

%As with other complex diseases, missing heritability has been a long-standing puzzle in cardiovascular diseases \citep{Manolio:2009:Finding}. Despite the early successes in pinpointing the causes of several monogenic diseases, the large body of genome-wide association (GWA) studies have defied many widely held beliefs about genetic variants in human, hinting at the directions to search for the missing heritability.


%rare variants. The most trivial situation where inherited risk is not fully accounted for is when the variants are simply too rare to be detected with sufficient power. One addresses this issue by collecting more samples or improving statistical tests. \comment{This reason has driven a lot of efforts to enlarge and diversify the study population, but I can't seem to get the relation RARE => PATHOGENIC.} The availability of a large number of genomes and exomes, on one hand enabled the detection of such rare variants, and on the others,  showed that rare variants 


\begin{figure*}[!tpb]
	\includegraphics[width=1.\linewidth]{hpo-gene-count}
	\caption{The number of genes associated with \textit{Abnormality of the cardiovascular system} (HP:0001626) as reported in the Human Phenotype Ontology \citep{Kohler:2014:Human}, with phenotype annotations pooled from OMIM, ORPHA and DECIPHER.}
	\label{fig:hpo_gene_count}	
\end{figure*}


\subsection{The diversity of actors}


\begin{figure*}[!tpb]
	%	\includegraphics[width=1\linewidth]{multiomics}
	\rule{2cm}{2cm}
	\caption{PLACE HOLDER - layers of omics data and the corresponding molecular assays. \comment{Genome, epigenome, transcriptome, proteome, metabolome, microbiome, exposome}}
	\label{fig:multiomics}
\end{figure*} 

Our understanding of CVD has been critically limited by the technical capability in characterizing various molecular fractions of a cell. GWA studies are predominantly conducted on SNPs thanks to the availability of easy-to-produce SNP microarrays. Such technologies have clearly enriched our knowledge base of single nucleotide variants, while leaving structural variations poorly understood. There are now 660 million of SNPs documented in dbSNP, compared to 4.6 millions of structural variations in the DGVa (Database of Genomic Variants Archive, which also includes studies annotated by the NCBI-hosted database of structural variants dbVar) \comment{number from Ensembl, but is it really this much?}. Structural variation databases such as dbVar and DGVa are in fact storing each study-publication individually instead of cataloging structural variations into data entries. Although the current knowledge base of structural variations is not sufficient to create reference entries of SV, the map of SV from 1000 Genomes Project \citep{Sudmant:2015:integrated} has enabled further studies of the role of SV in cardiac diseases, suggesting the potential impact of SV on the transcriptional regulation of cardiac genes expressed in the heart \citep{Haas:2018:Genomic}. As envisioned, structural variations might be one of the promising lands to look for the missing heritability in CVD \citep{Eichler:2010:Missing}.

% non-coding
When array-based genotyping was gradually replaced by next-generation sequencing, the cost of sequencing an \textit{exome}, the protein-coding part of a genome, became much more affordable and enabled the collection of more than 60000 exomes \citep{Lek:2016:Analysis}. Using this data set, \cite{Walsh:2017:Reassessment} have found that many genetic variants associated with various cardiomyopathy diseases turned out to be equally common in clinical cases as in the control population. Genes that were consistently included on genetic testing panels for DCM such as MYBPC3, MYH6, SCN5A, etc. turned out to contribute much less etiology than previously thought, in consideration of their frequency in the control population.

The rationale for prioritizing the sequencing of exome over that of the entire genome is based on a regularly cited statement that exome harbors 85\% of the disease-causing variants \citep{Antonarakis:2001:nature}. This figure turns out to be an outdated estimate from 1995. Among the variation-phenotype associations curated in the GWAS catalog \citep{MacArthur:2017:new}, a large fraction of variants occur in non-protein coding regions such as intronic, intergenic, and splice junctions (Figure \ref{fig:variant_context}). Interestingly, the distribution of CVD-associated variants mimics that of the all-variant set, suggesting that variants accounting for human traits, neutral or disease-causing, might be distributed in the same manner across the genome. Previous studies also asserted the prevalence of regulatory regions among variants associated with cardiometabolic risk \citep{Franzen:2016:Cardiometabolic}, as well as many other complex traits \citep{Pickrell:2014:Joint}. As an unprecedented amount of whole-genome sequencing data become available from large-scale genomic projects such as 1000G, TOPMed, CCDG \comment{add refs, tabulate the number of participants and links to project}, we are poised to learn more about this dark matter in the human genome and how it works in complex diseases.

%epigenetics
Cardiovascular risks can be conferred with modifications beyond genomic sequence, collectively studied as epigenetics. Epigenetic processes traditionally involved DNA methylation, a wide range of histone modifications including acetylation, methylation, phosphorylation, uniquitylation, sumoylation and biotinylation, and are now encompassing more processes mediated by the class of long non-coding RNAs (lncRNA). Early differential epigenomic analysis, albeit on limited number of samples, established differentiating features in DNA methylation and histone H3 methylation between control and failing hearts \citep{Movassagh:2011:Distinct}, probing more epigenomic research in cardiovascular diseases. Following these early findings, epigenome-wide association studies are proposing a number of DNA methylation sites associated with blood lipid \citep{Irvin:2014:Epigenomewide}, body mass index \citep{Dick:2014:DNA, Wahl:2017:Epigenomewide}, heart failure \citep{Meder:2017:EpigenomeWide}, heart attack history \citep{Rask-Andersen:2016:Epigenomewide}.
When more lncRNAs were discovered and characterized, the prevalence of these molecules in cardiovascular biology also emerged. LncRNAs are involved in coronary artery disease, myocardial infarction, cardiac hypertrophy, etc. \comment{should we add more details?}  At least 22 lncRNAs were reportedly dis-regulated in cardiovascular diseases, affecting a wide range of molecular, cellular and physiological processes \citep{Das:2018:Deciphering}. With 107,039 lncRNAs detected in the human genome so far (reported by LNCipedia \citep{Volders:2018:LNCipedia}, as of November 2018), more lncRNAs are likely to be found involved in cardiovascular biology, hence promising therapeutic targets.
% cardiac differentiation, histone methylation, sponge of microRNAs, apoptosis
%angiogenesis, inflammation, macrophage activation, sarcomere development, autophagy
Mapping the epigenome involves a highly diverse set of experimental assays. DNA methylation profiling can be done with methylation-sensitive restriction enzymes, bisulfite sequencing, or immunoprecipitation with antibodies against  methylated-cytosine \citep{Bibikova:2010:Genomewide}. Histone modifications can be profiled by immunoprecipitation with antibodies specific to the modified histone of interest, essentially requiring a ChIP experiment for each of the histone modification one wants to interrogate. Meanwhile, the non-coding RNA transcripts can be profiled with variants of RNA-seq that are optimized for the target fraction of RNAs. Such diversity entails significant difficulty in comprehensive assay of the epigenome in a single experimental study, stressing the need for re-collection and re-analysis of dispersed data sets for a more complete picture.

%Epigenetic studies supplemented significant mechanistic insights to understand complex conditions  such as atherosclerosis \citep{Xu:2018:Targeting}. 

%Difficulty in studying lncRNAs: low abundance level, highly tissue-specific expression. Approaches to study lncRNAs \citep{Sallam:2018:Long}

%A range of functions have been reported for lncRNAs, including imprinting, scaffolding, enhancer, and molecular sponges. More research is certainly needed to obtain a complete catalog of lncRNA functions. \comment{role of non-coding RNAs and epigenetics in cardiovascular biology \citep{Sallam:2018:Long}}

\comment{to be added -- chromatin conformation \citep{Rosa-Garrido:2017:HighResolution}}

%environment interactions

It has been known for decades that non-genetic factors play a critical role in cardiovascular health, such that a risk prediction using lifestyle variables perform much better than a gene-count score \citep{Joyner:2011:Ten}. Although such interactions are of focal interest to cardiovascular epidemiology,  the understanding of them at the molecular level have been restricted due to the difficulties in measuring the numerous agents in an exposome, i.e. all environmental exposures throughout life, including one's diet, pollutants, infections \citep{Wild:2005:Complementing}. Continual improvement of existing chemical profiling methods including mass spectronomy (MS), LC-MS, GC-MS, and their variations, has enabled the detection of hundred thousands of xenobiotic compounds \comment{check for specific number on state-of-the art facility} in human urine and blood samples \citep{Warth:2017:ExposomeScale}.
Recent development of wearable devices can now collect real time data in a non-intrusive manner, allowing for dynamic monitoring of the exposome \citep{Jiang:2018:Dynamic}. As complex traits being heavily influenced by environmental factors, cardiovascular diseases are especially well-positioned to benefit from the advancement of exposome measurement.


%\subsection{The complex actions}

From a molecular perspective, a phenotype can be influenced at any stage, starting from the DNA sequence, to the chromatin structures and modifications, down to RNA transcripts, proteins and metabolites \comment{Figure \ref{fig:multiomics}}. Accordingly, a gene (and its variants) may exert its effect in various modes.


Heritability of complex diseases has been modeled on the assumption that contributions of genes are additive. Many examples have refuted that assumption, suggesting that the effects of genes can be compensatory, or synergistic.

homeostasis


%Accordingly, the number of biological states is exponential. Among these states, it is obvious that biological systems do not seek for a single optimal state, but always strive for the most convenient functional one. Therefore, it is reasonable to expect a diverse set of states in which biological system is equivalently functional.



\begin{figure}[!tpb]
	\includegraphics[width=1\linewidth]{variant_contexts_sigVars}
	\caption{Distribution of known variants that have been associated with a phenotypic trait in the human genome. The associations are downloaded from GWAS catalog \citep{MacArthur:2017:new} in which only those with p-value less than $10^{-5}$ were retained. \comment{Trang: group the contexts into 4 catergories: intronic, splice, intergenic and exonic regions, either by colors or additional chart.}}
	\label{fig:variant_context}
\end{figure}

%Some quantity showing the associations of CVD with genes...
%




%
\section{Cardioinformatics}
%%
As demonstrated earlier, the large number of studies have contributed to a larger, not necessarily more solid, body of knowledge. In the following section, we argue for the readiness and the prospect of cardioinformatics, by looking at the current infrastructure for biological data analytics, the computational methods.

\subsection{The soil is worked}

\comment{This part is to introduce the achievements and on-going work in developing the infrastructure for data storage, management and sharing, thus making the case for an invest in bioinformatics analyses to capitalize on these resources.}


\subsubsection{Profusion of data}

Biological data has steadily increased, in both the number of data points, and the number of dimensions in each data point.
Major classes of biological molecules including DNA, RNA, and protein can now be characterized and/or quantified with high-throughput techniques. The output of these assays is essentially a giant vector on the order of $10^3$ to $10^5$ elements depending on the type of molecule and technology \comment{table of molecule type -- contemporary tech -- number of species per tech might be interesting. may not be very useful though}. Central repositories such as GEO and dbGaP have accumulated an immense number of assays, effectively increasing the number of data points available for future studies.
In the Gene Expression Omnibus (GEO), CVD publications have contributed more than 2000 microarray datasets, and about 900 of high-throughput sequencing datasets for various purposes (Figure \ref{fig:geo-assay}). Especially abundant are mRNA-seq assays, performed as the main assay in most studies, and usually coupled with another profiling technique. In dbGaP where human genotype-phenotype data are deposited, CVD research has collected data on 658305 subjects, 16786 (2.5\%) of which had consented for the data to be employed for general research (Table \ref{tab:dbgapSubject}), leaving a vast majority of data accessible only upon approval of data request.

%Depending on the questions at hands, the precise definition of a data point can vary. In most cases, it can be equivalent to the number biological samples or that of individual donors. Although studies directly related to CVDs are of interest when it comes to future CVD research, a significant number of data points from non-CVD studies can be put into use, for example, when these studies investigated samples of cardiovascular origin (heart or vascular tissues).

\begin{figure*}[!tpb]
	\includegraphics[width=1\linewidth]{assay-count-cardio}
	\caption{(\textbf{A}) The cumulative number of molecular assays \comment{(i.e. unique combinations of biosample, study and platform)} deposited on GEO by cardiovascular research. (\textbf{B}) Breakdown of high-throughput sequencing assays by the type of study.}
	\label{fig:geo-assay}\comment{To avoid excessive overcounting of irrelevant samples such as those from plants or unrelated model organisms, we only counted samples deposited with a Pubmed ID pointing to a cardiovascular study. Surveys were done on the GEOmetadb database \citep{Zhu:2008:GEOmetadb} updated on 2018/11/17.}
\end{figure*} 

%\begin{table}[!t]
%	\processtable{Number of samples available on GEO that are of potential use of cardioinformatics research, including those deposited by CVD studies and non-CVD studies.\label{tab:geoSamples}} {\begin{tabular}{@{}llll@{}}\toprule 
%			molecule &non-CVD studies & CVD studies \\ \midrule
%			genomic DNA &            440 &        8525  \\
%			polyA RNA &             89 &         392  \\
%			total RNA &           2974 &       39540  \\
%			other &             NA &           5  \\
%			protein &             NA &           3  \\ \botrule
%	\end{tabular}}{This is a footnote}
%\end{table}

%The figures given in Table \ref{tab:dbgapSubject} are in fact the conservative estimates of the data generated so far among the research community. A much larger amount of data are stored on dbGaP and accessible upon approval of data request. Among these, the number of subjects involved in CVD research alone are more than 600000. %658305 to be exact
%In term of subject count, the amount of data from CVD-related studies permitted for General Research Use is only
% 16786 / 658305
%2.5\% of all the CVD-related studies deposited on dbGaP.

\comment{supplement table if necessary}

Aside from central authoritative repositories of research data, smaller databases with narrower focus are budding. For example, many databases have been created to collect chromatin structure data from 3C, 4C, 5C and HiC-seq experiments. A few databases are actively gathering knowledge about non-coding RNAs. Being in these under-explored territories, researchers may need more work to collect and curate their data from multiple sources before using them for further analyses.



A list of databases focusing on human genotype-phenotype data was already presented elsewhere \citep{Brookes:2015:Human}, illustrating the expansion of data available to biomedical research. 

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
	\caption{The subject count aggregated from studies deposited in dbGaP, consented for General Research Use (GRU)}
	\label{tab:dbgapSubject}
	\begin{tabular}{l l l}
		\toprule
		& \textbf{CVD} &  \textbf{All}                         \\ \midrule
		16s rRNA (NGS)                 &     0 &      92 \\
		CNV Genotypes                  &     0 &   48972 \\
		Chromatin (NGS)                &     0 &     139 \\
		Genomic Sequence Amplicon (NGS)&     0 &       8 \\
		Methylation (CpG)              &     0 &     657 \\
		Methylome sequencing           &     0 &     152 \\
		QTL Results                    &     0 &     281 \\
		RNA Seq (NGS)                  &   333 &    1498 \\
		SNP Genotypes (Array)          &  6658 &  113597 \\
		SNP Genotypes (NGS)            &  4277 &   11786 \\
		SNP Genotypes (PCR)            &     0 &      10 \\
		SNP Genotypes (imputed)        &     0 &   29693 \\
		SNP/CNV Genotypes (NGS)        &     0 &     936 \\
		SNP/CNV Genotypes (imputed)    &     0 &    9291 \\
		SNV (.MAF)                     &     0 &       2 \\
		SNV Aggregate (.MAF)           &     0 &     570 \\
		Targeted Genome (NGS)          &     0 &    9918 \\
		Whole Exome (NGS)              &  5518 &   12771 \\
		Whole Genome (NGS)             &     0 &    1245 \\
		mRNA Expression (Array)        &     0 &     798 \\
		miRNA (NGS)                        & 0 &   228 \\ \hline
		Total subject count in data consented for GRU & 16786 & 242644 \\ \hline
		All consent groups & 658305 & Unknown \\	
	\end{tabular}
\end{table}

The data from non-CVD studies are of great potential use as the baseline, for example when comparing the normal vs disease state, general vs clinical population. Moreover, assays on non-cardiac and non-vascular tissues are indispensable in identifying the transcripts with expression specific to the cardiovascular system.

\subsubsection{Infrastructure}

Large amount of data imposed critical challenges in storing, managing and computing. The Sequence Read Archive (SRA) is now home to 14 petabases of sequencing data from 100000 studies \citep{Langmead:2018:Cloud}.
%With more than 400000 RNA-seq runs, each taking 2GB \citep{Langmead:2018:Cloud}, the space required to simply store these data on the Sequence Read Archive (SRA) database amounts to 800 TB.
Although the storage required to store the raw output of high-throughput sequencing experiments are certainly exceeding the capability of an average computing facility, the major challenge is turning these archives into easily accessible databases, especially under the legal and ethical requirements to protect participants' privacy.
As illustrated in Table \ref{tab:dbgapSubject}, there are 658305 records of genotype-phenotype data potentially relevant to future biomedical studies. To access these data, one needs to file a request, prepare the facility, implement the security measures, and transfer the data upon approval. However, before filing a request, one needs to dive into the metadata of individual studies and decide which data sets are useful for the target research. Important information about a dataset such as the list of phenotypic variables are vastly different from study to study and cannot be filtered against. In addition to those parameters of a study design, researchers need to be aware of the various types of consents applied to different data sets, many times within a single study. This procedure to obtain data access is currently applied for all control-accessed data in dbGaP, adding a significant administrative burden to biomedical researchers.
As an effort towards more accessible biomedical data, the AHA Precision Medicine Platform \citep{Kass-Hout:2018:American} has simplified this process by streamlining the search, request and transfer of data. Data sets deposited on the platform were harmonized such that users can query for data across multiple studies by some common parameters, selectively request access to the relevant data, and perform analyses on the cloud-based workspace.
Although the data filtering step is greatly facilitated, data can only be delivered to a restricted community who had been granted access and became responsible for securing their copy of the control-accessed data. In the attempt to alleviate all the responsibilities associating with the direct access of sensitive data, the DataSHIELD platform has been developed \citep{Gaye:2014:DataSHIELD, Wilson:2017:DataSHIELD}. This platform allows data users to perform analytics without disclosure of sensitive or identifiable information.
%more applications \citep{Wilson:2017:DataSHIELD}.

Bioinformatics analyses have also started to benefit from cloud-based computing.
A number of projects have successfully re-processed and re-analyzed the large amount of biological samples across large databases such as TCGA, dbGaP, etc., providing novel insights or cloud-compatible analytics protocols, such as Rail-dbGaP \citep{Nellore:2016:RaildbGaP}, Toil \citep{Vivian:2017:Toil}. These successes on one hand demonstrate the great potential of existing data sets, and on the other, provide concrete examples on how cloud-based computing can be performed, to overcome huge requirements of storage, memory and computational power. More than 20 providers are provisioning cloud services in both commercial and academic sectors \citep{Langmead:2018:Cloud}, promising even lower cost and higher accessibility.


%Guidelines, protocol
%Data visibility
%efforts to standardize data management and sharing
%

\subsection{Computational tools}

As early as 1999 when the complete human genome and high-throughput transcriptomic profiling are on the horizon, research community have started to recognize the critical use of bioinformatics analyses in generating insights from these data. The computational approaches outlined by \cite{Claverie:1999:Computational} for the early day gene expression data are still popular in today transcriptomics studies: differential gene expression analysis, co-expression analysis and gene clustering with subsequent identification of enriched biological pathways. Those old-fashioned methods can still bring fruitful analyses, as illustrated in a recent study on heart failure \citep{Santolini:2018:personalized}. With more samples piling up from individual studies, such analyses can be performed with potentially more statistical power. \comment{IMPORTANT -- find good examples}

As high-throughput technology was expanded to cover different molecular aspects of a cellular processes, the potential power of integrative analysis on multiple layers of -omics data has been recognized as early as a decade ago \citep{Hawkins:2010:Nextgeneration}. Since then, various strategies have been developed, following one of the two schemes: multi-staged or meta-dimensional \cite{Ritchie:2015:Methods}. Multi-staged data integration has been routinely used in cardiovascular research, for example in the search of expression quantitative trait (eQTL) loci, SNPs resulted from previous GWAS are tested for correlation with gene expression levels from transcriptomics profiling data. Meta-dimensional data integration does not rely on the assumption that phenotype is the end point of the one-way flow of information from genome, to transcriptome and then proteome, thus allowing for modeling of complex phenotype without prior knowledge about the interplay of different omics layers.
\comment{find examples -- in and outside of CVDs}

%* proteomics + transcriptomics \citep{Uhlen:2015:Tissuebased}
%
%* genomics + transcriptomics \citep{Klarin:2017:Genetic}

\comment{[ML -- not fit yet]}
The application of machine learning will be indispensable in many aspects of cardiology \citep{Shameer:2017:Translational,Shameer:2018:Machine}. Given the availability of machine learning performant implementations, cardioinformatics is better positioned to tackle domain-specific questions and develop clinical application. For example, ML can be applied to enhance medical image. In basic research, natural language processing can be a promising tool to improve data collection and organization.

Although not a traditional part of computational research, visualization has become indispensable in data-driven research, facilitating biological research in data exploration, pattern recognition, and data representation. Visualization methods are blooming to accommodate the diverse data types in biology \citep{Pavlopoulos:2015:Visualizing}. In this arena, the exciting challenge to cardioinformatics researchers is how to integrate and represent data layers in a meaningful manner.
%In clinical application, the focus is on facilitating clinical decisions.

%Visualization of chromatin 3D structure emerges as a demand to analyze and present experimental data from conformation capture experiments. The challenges posed by these experiments, being new, high-throughput and  3-dimensional, are actively researched visualization problems \citep{Goodstadt:2017:Challenges}. As a researcher in cardiovascular disease, it is important to stay abreast with the developments in this field to make the most use of the available data.

Search engine and knowledge synthesis \citep{Lutjohann:2011:Sciencenet}. A universal element of all research, knowledge synthesis is under-rated research task. Like most other areas, most of the work in knowledge synthesis has been and has to be done manually in cardiovascular research. Cardiovascular diseases impose the challenge of understanding complex systems of multiple dimensions, creating the pressing need of summarizing and synthesizing knowledge from the vast body of research in a more robust manner. \comment{Natural language processing?}


Most often, the bottleneck in the application of these computational methods are not in their implementation, but in the shortage of domain knowledge. Many generic bio-portals have been published in the recent years, aiming to make complicated data as accessible as possible to a general audience. The lack of focus on a research topic has limited their usefulness.

%%%%%% perspective
Bioinformatics provides more than the powerful toolkits to study cardiovascular diseases. Important perspectives have arisen from the application of computational methodology. The paradigm shift from the physical genes to the "eigengenes" in studying complex diseases \citep{Weiss:2012:Good} is an example. This approach allows one to focus on mimicking the healthy system without the knowledge required to model the individual actors and their interactions, making it an ideal method in the drug discovery workflow. The paradigm can help advancing knowledge further because it suggests an efficient way to engineer biological system and learn how it works.
\comment{omnigenic, and some more when I remember}


\subsection{Prospective development}

nanopore sequencing

single cell



\section{Conclusion}


%

\enlargethispage{12pt}




\section*{Acknowledgements}

Text Text Text Text Text Text  Text Text.  
\vspace*{-12pt}

\section*{Funding}

This work has been supported by the... Text Text  Text Text.\vspace*{-12pt}

\bibliographystyle{natbib}
%\bibliographystyle{achemnat}
%\bibliographystyle{plainnat}
%\bibliographystyle{abbrv}
%
%\bibliographystyle{plain}
%
\bibliography{cardio}



\end{document}
